{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnth/mambaforge-pypy3/envs/xinfer-test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                     Available Models                                     </span>\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Implementation </span>┃<span style=\"font-weight: bold\"> Model ID                                        </span>┃<span style=\"font-weight: bold\"> Input --&gt; Output    </span>┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_m38m_ft_in22k_in1k  </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_m38m_ft_in1k        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_in22k_ft_in22k_in1k </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_in22k_ft_in1k       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_base_patch14_448.mim_in22k_ft_in22k_in1k  </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_base_patch14_448.mim_in22k_ft_in1k        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_small_patch14_336.mim_in22k_ft_in1k       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_tiny_patch14_336.mim_in22k_ft_in1k        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b-coco                  </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-flan-t5-xxl                    </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b                       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-2.7b                       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> vikhyatk/moondream2                             </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8x                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8m                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8l                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8s                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8n                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov10x                                        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov10m                                        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ...            </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ...                                             </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> ...                 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ...            </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ...                                             </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> ...                 </span>│\n",
       "└────────────────┴─────────────────────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                     Available Models                                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mImplementation\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mModel ID                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInput --> Output   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_m38m_ft_in22k_in1k \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_m38m_ft_in1k       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_in22k_ft_in22k_in1k\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_in22k_ft_in1k      \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_base_patch14_448.mim_in22k_ft_in22k_in1k \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_base_patch14_448.mim_in22k_ft_in1k       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_small_patch14_336.mim_in22k_ft_in1k      \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_tiny_patch14_336.mim_in22k_ft_in1k       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b-coco                 \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-flan-t5-xxl                   \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b                      \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-2.7b                      \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mvikhyatk/moondream2                            \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8x                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8m                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8l                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8s                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8n                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov10x                                       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov10m                                       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m...           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m...                                            \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m...                \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m...           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m...                                            \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m...                \u001b[0m\u001b[32m \u001b[0m│\n",
       "└────────────────┴─────────────────────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xinfer\n",
    "\n",
    "xinfer.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-17 02:46:28.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.timm.timm_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mModel: eva02_small_patch14_336.mim_in22k_ft_in1k\u001b[0m\n",
      "\u001b[32m2024-10-17 02:46:28.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.timm.timm_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mDevice: cuda\u001b[0m\n",
      "\u001b[32m2024-10-17 02:46:28.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.timm.timm_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mDtype: bfloat16\u001b[0m\n",
      "\u001b[32m2024-10-17 02:46:28.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.timm.timm_model\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mLoading model: eva02_small_patch14_336.mim_in22k_ft_in1k\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = xinfer.create_model(\"eva02_small_patch14_336.mim_in22k_ft_in1k\", device=\"cuda\", dtype=\"bfloat16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1017 02:46:41.398000 130848176174912 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'class': 'trolleybus, trolley coach, trackless trolley',\n",
       "  'id': 874,\n",
       "  'confidence': 87.0},\n",
       " {'class': 'streetcar, tram, tramcar, trolley, trolley car',\n",
       "  'id': 829,\n",
       "  'confidence': 3.59375},\n",
       " {'class': 'minibus', 'id': 654, 'confidence': 2.25},\n",
       " {'class': 'passenger car, coach, carriage',\n",
       "  'id': 705,\n",
       "  'confidence': 0.6640625},\n",
       " {'class': 'amphibian, amphibious vehicle',\n",
       "  'id': 408,\n",
       "  'confidence': 0.1396484375},\n",
       " {'class': 'school bus', 'id': 779, 'confidence': 0.12890625},\n",
       " {'class': 'Loafer', 'id': 630, 'confidence': 0.1083984375},\n",
       " {'class': 'traffic light, traffic signal, stoplight',\n",
       "  'id': 920,\n",
       "  'confidence': 0.0830078125},\n",
       " {'class': 'street sign', 'id': 919, 'confidence': 0.0712890625},\n",
       " {'class': 'fur coat', 'id': 568, 'confidence': 0.06787109375}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer(\"https://ultralytics.com/images/bus.jpg\", top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Model Stats                               </span>\n",
       "╭───────────────────────────┬───────────────────────────────────────────╮\n",
       "│<span style=\"font-weight: bold\"> Attribute                 </span>│<span style=\"font-weight: bold\"> Value                                     </span>│\n",
       "├───────────────────────────┼───────────────────────────────────────────┤\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Model ID                  </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_small_patch14_336.mim_in22k_ft_in1k </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Device                    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> cuda                                      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Dtype                     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> torch.bfloat16                            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Number of Inferences      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 3                                         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Total Inference Time (ms) </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 8599.7230                                 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Average Latency (ms)      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 2866.5743                                 </span>│\n",
       "╰───────────────────────────┴───────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Model Stats                               \u001b[0m\n",
       "╭───────────────────────────┬───────────────────────────────────────────╮\n",
       "│\u001b[1m \u001b[0m\u001b[1mAttribute                \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mValue                                    \u001b[0m\u001b[1m \u001b[0m│\n",
       "├───────────────────────────┼───────────────────────────────────────────┤\n",
       "│\u001b[36m \u001b[0m\u001b[36mModel ID                 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_small_patch14_336.mim_in22k_ft_in1k\u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mDevice                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mcuda                                     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mDtype                    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtorch.bfloat16                           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mNumber of Inferences     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m3                                        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTotal Inference Time (ms)\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m8599.7230                                \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAverage Latency (ms)     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m2866.5743                                \u001b[0m\u001b[35m \u001b[0m│\n",
       "╰───────────────────────────┴───────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUTOTUNE convolution(2x3x336x336, 384x3x14x14)\n",
      "  triton_convolution_940 0.1495 ms 100.0%\n",
      "  triton_convolution_942 0.1874 ms 79.8%\n",
      "  triton_convolution_939 0.2153 ms 69.4%\n",
      "  triton_convolution_937 0.2191 ms 68.2%\n",
      "  triton_convolution_941 0.2263 ms 66.1%\n",
      "  convolution 0.2867 ms 52.1%\n",
      "  triton_convolution_936 0.3697 ms 40.4%\n",
      "  triton_convolution_938 0.6318 ms 23.7%\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.0315 seconds and 0.0008 seconds precompiling\n",
      "W1017 02:47:26.271000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1017 02:47:26.618000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1017 02:47:27.211000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE addmm(1154x1152, 1154x384, 384x1152)\n",
      "  triton_mm_949 0.0236 ms 100.0%\n",
      "  triton_mm_950 0.0246 ms 95.8%\n",
      "  triton_mm_946 0.0266 ms 88.5%\n",
      "  triton_mm_948 0.0266 ms 88.5%\n",
      "  triton_mm_952 0.0266 ms 88.5%\n",
      "  triton_mm_953 0.0266 ms 88.5%\n",
      "  triton_mm_956 0.0266 ms 88.5%\n",
      "  triton_mm_945 0.0274 ms 85.9%\n",
      "  triton_mm_957 0.0276 ms 85.2%\n",
      "  triton_mm_954 0.0287 ms 82.1%\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1269 seconds and 0.0016 seconds precompiling\n",
      "W1017 02:47:28.265000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1017 02:47:28.616000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1017 02:47:29.204000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(1154x384, 384x384)\n",
      "  triton_mm_975 0.0115 ms 100.0%\n",
      "  triton_mm_964 0.0123 ms 93.7%\n",
      "  triton_mm_968 0.0123 ms 93.7%\n",
      "  triton_mm_971 0.0123 ms 93.7%\n",
      "  triton_mm_973 0.0123 ms 93.7%\n",
      "  triton_mm_965 0.0124 ms 93.0%\n",
      "  triton_mm_972 0.0131 ms 87.8%\n",
      "  mm 0.0133 ms 86.5%\n",
      "  triton_mm_969 0.0133 ms 86.5%\n",
      "  triton_mm_976 0.0133 ms 86.5%\n",
      "SingleProcess AUTOTUNE benchmarking takes 1.9929 seconds and 0.0010 seconds precompiling\n",
      "W1017 02:47:30.289000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1017 02:47:30.650000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1017 02:47:31.248000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(1154x384, 384x2048)\n",
      "  triton_mm_987 0.0328 ms 100.0%\n",
      "  triton_mm_990 0.0328 ms 100.0%\n",
      "  triton_mm_994 0.0328 ms 100.0%\n",
      "  triton_mm_991 0.0338 ms 97.0%\n",
      "  triton_mm_997 0.0338 ms 97.0%\n",
      "  mm 0.0348 ms 94.1%\n",
      "  triton_mm_988 0.0348 ms 94.1%\n",
      "  triton_mm_992 0.0348 ms 94.1%\n",
      "  triton_mm_995 0.0348 ms 94.1%\n",
      "  triton_mm_986 0.0350 ms 93.6%\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0418 seconds and 0.0014 seconds precompiling\n",
      "W1017 02:47:32.311000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1017 02:47:32.674000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 147456, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "W1017 02:47:33.276000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 131072, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE mm(1154x1024, 1024x384)\n",
      "  triton_mm_1009 0.0225 ms 100.0%\n",
      "  triton_mm_1013 0.0225 ms 100.0%\n",
      "  mm 0.0236 ms 95.7%\n",
      "  triton_mm_1002 0.0236 ms 95.7%\n",
      "  triton_mm_1003 0.0236 ms 95.7%\n",
      "  triton_mm_1010 0.0236 ms 95.5%\n",
      "  triton_mm_1006 0.0246 ms 91.7%\n",
      "  triton_mm_1007 0.0246 ms 91.7%\n",
      "  triton_mm_1011 0.0246 ms 91.7%\n",
      "  triton_mm_1014 0.0256 ms 88.0%\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.0268 seconds and 0.0012 seconds precompiling\n",
      "W1017 02:47:34.939000 130848176174912 torch/_inductor/select_algorithm.py:1469] [0/1] out of resource: shared memory, Required: 110592, Hardware limit: 101376. Reducing block sizes or `num_stages` may help.\n",
      "AUTOTUNE addmm(2x1000, 2x384, 384x1000)\n",
      "  triton_mm_1857 0.0061 ms 100.0%\n",
      "  triton_mm_1859 0.0072 ms 85.7%\n",
      "  triton_mm_1862 0.0072 ms 85.7%\n",
      "  triton_mm_1863 0.0072 ms 85.7%\n",
      "  triton_mm_1865 0.0072 ms 85.7%\n",
      "  triton_mm_1866 0.0072 ms 85.7%\n",
      "  triton_mm_1869 0.0072 ms 85.7%\n",
      "  triton_mm_1858 0.0074 ms 83.5%\n",
      "  triton_mm_1856 0.0082 ms 75.0%\n",
      "  triton_mm_1864 0.0082 ms 75.0%\n",
      "SingleProcess AUTOTUNE benchmarking takes 2.1256 seconds and 0.0009 seconds precompiling\n",
      "W1017 02:47:35.694000 130848176174912 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'class': 'trolleybus, trolley coach, trackless trolley',\n",
       "   'id': 874,\n",
       "   'confidence': 87.0},\n",
       "  {'class': 'streetcar, tram, tramcar, trolley, trolley car',\n",
       "   'id': 829,\n",
       "   'confidence': 3.71875},\n",
       "  {'class': 'minibus', 'id': 654, 'confidence': 2.171875},\n",
       "  {'class': 'passenger car, coach, carriage',\n",
       "   'id': 705,\n",
       "   'confidence': 0.6640625},\n",
       "  {'class': 'amphibian, amphibious vehicle',\n",
       "   'id': 408,\n",
       "   'confidence': 0.1396484375},\n",
       "  {'class': 'school bus', 'id': 779, 'confidence': 0.130859375},\n",
       "  {'class': 'Loafer', 'id': 630, 'confidence': 0.10693359375},\n",
       "  {'class': 'traffic light, traffic signal, stoplight',\n",
       "   'id': 920,\n",
       "   'confidence': 0.08056640625},\n",
       "  {'class': 'street sign', 'id': 919, 'confidence': 0.07080078125},\n",
       "  {'class': 'fur coat', 'id': 568, 'confidence': 0.0654296875}],\n",
       " [{'class': 'trolleybus, trolley coach, trackless trolley',\n",
       "   'id': 874,\n",
       "   'confidence': 87.0},\n",
       "  {'class': 'streetcar, tram, tramcar, trolley, trolley car',\n",
       "   'id': 829,\n",
       "   'confidence': 3.71875},\n",
       "  {'class': 'minibus', 'id': 654, 'confidence': 2.171875},\n",
       "  {'class': 'passenger car, coach, carriage',\n",
       "   'id': 705,\n",
       "   'confidence': 0.6640625},\n",
       "  {'class': 'amphibian, amphibious vehicle',\n",
       "   'id': 408,\n",
       "   'confidence': 0.1396484375},\n",
       "  {'class': 'school bus', 'id': 779, 'confidence': 0.130859375},\n",
       "  {'class': 'Loafer', 'id': 630, 'confidence': 0.10693359375},\n",
       "  {'class': 'traffic light, traffic signal, stoplight',\n",
       "   'id': 920,\n",
       "   'confidence': 0.08056640625},\n",
       "  {'class': 'street sign', 'id': 919, 'confidence': 0.07080078125},\n",
       "  {'class': 'fur coat', 'id': 568, 'confidence': 0.0654296875}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_batch([\"https://ultralytics.com/images/bus.jpg\", \"https://ultralytics.com/images/bus.jpg\"], top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xinfer.timm import TimmModel\n",
    "\n",
    "model = TimmModel(\"resnet18\", device=\"cuda\", dtype=\"bfloat16\")\n",
    "model = xinfer.create_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xinfer.create_model(\"eva02_tiny_patch14_336.mim_in22k_ft_in1k\")\n",
    "\n",
    "result = model.infer(\"../assets/xinfer.jpg\", top_k=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xinfer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
