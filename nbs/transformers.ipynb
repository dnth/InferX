{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                     Available Models                                     </span>\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Implementation </span>┃<span style=\"font-weight: bold\"> Model ID                                        </span>┃<span style=\"font-weight: bold\"> Input --&gt; Output    </span>┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_m38m_ft_in22k_in1k  </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_m38m_ft_in1k        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_in22k_ft_in22k_in1k </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_large_patch14_448.mim_in22k_ft_in1k       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_base_patch14_448.mim_in22k_ft_in22k_in1k  </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_base_patch14_448.mim_in22k_ft_in1k        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_small_patch14_336.mim_in22k_ft_in1k       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> timm           </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> eva02_tiny_patch14_336.mim_in22k_ft_in1k        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; class     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b-coco                  </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-flan-t5-xxl                    </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-6.7b                       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Salesforce/blip2-opt-2.7b                       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> transformers   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> vikhyatk/moondream2                             </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image-text --&gt; text </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8x                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8m                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8l                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8s                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov8n                                         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov10x                                        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ultralytics    </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> yolov10m                                        </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> image --&gt; objects   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ...            </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ...                                             </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> ...                 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ...            </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> ...                                             </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> ...                 </span>│\n",
       "└────────────────┴─────────────────────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                     Available Models                                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mImplementation\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mModel ID                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInput --> Output   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_m38m_ft_in22k_in1k \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_m38m_ft_in1k       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_in22k_ft_in22k_in1k\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_large_patch14_448.mim_in22k_ft_in1k      \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_base_patch14_448.mim_in22k_ft_in22k_in1k \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_base_patch14_448.mim_in22k_ft_in1k       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_small_patch14_336.mim_in22k_ft_in1k      \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtimm          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35meva02_tiny_patch14_336.mim_in22k_ft_in1k       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> class    \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b-coco                 \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-flan-t5-xxl                   \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-6.7b                      \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSalesforce/blip2-opt-2.7b                      \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtransformers  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mvikhyatk/moondream2                            \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage-text --> text\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8x                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8m                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8l                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8s                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov8n                                        \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov10x                                       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36multralytics   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35myolov10m                                       \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mimage --> objects  \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m...           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m...                                            \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m...                \u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m...           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m...                                            \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m...                \u001b[0m\u001b[32m \u001b[0m│\n",
       "└────────────────┴─────────────────────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xinfer\n",
    "\n",
    "# xinfer.list_models(\"vlrm-blip2-opt-2.7b\")\n",
    "xinfer.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8e40b4957845e1a534812be27f78d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = xinfer.create_model(\"vikhyatk/moondream2\")\n",
    "# model = xinfer.create_model(\"microsoft/git-base-coco\", \"transformers\", trust_remote_code=True)\n",
    "model = xinfer.create_model(\"Salesforce/blip2-opt-2.7b\")\n",
    "# model = xinfer.create_model(\"sashakunitsyn/vlrm-blip2-opt-2.7b\", \"transformers\")\n",
    "# model = xinfer.create_model(\"microsoft/kosmos-2-patch14-224\", \"transformers\")\n",
    "\n",
    "\n",
    "# model = xinfer.create_model(\n",
    "#     \"llava-hf/llava-onevision-qwen2-0.5b-ov-hf\",\n",
    "#     \"transformers\"\n",
    "# )\n",
    "\n",
    "# from xinfer.transformers import Vision2SeqModel\n",
    "\n",
    "# model = Vision2SeqModel(\"facebook/chameleon-7b\")\n",
    "# model = xinfer.create_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Local file not found: ../assets/xinfer.jg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/xinfer/xinfer/transformers/auto.py:55\u001b[0m, in \u001b[0;36mVision2SeqModel.preprocess\u001b[0;34m(self, images, prompts)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/xinfer/lib/python3.10/site-packages/PIL/Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../assets/xinfer.jg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# prompt = \"<grounding> An image of\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../assets/xinfer.jg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m generated_text\n",
      "File \u001b[0;32m~/Desktop/xinfer/xinfer/transformers/auto.py:77\u001b[0m, in \u001b[0;36mVision2SeqModel.infer\u001b[0;34m(self, image, prompt, verbose, **generate_kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, prompt, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs):\n\u001b[1;32m     76\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m---> 77\u001b[0m     preprocessed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(preprocessed_input, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[1;32m     79\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(prediction)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/xinfer/xinfer/transformers/auto.py:57\u001b[0m, in \u001b[0;36mVision2SeqModel.preprocess\u001b[0;34m(self, images, prompts)\u001b[0m\n\u001b[1;32m     55\u001b[0m             image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocal file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m     processed_images\u001b[38;5;241m.\u001b[39mappend(image)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor(\n\u001b[1;32m     62\u001b[0m     images\u001b[38;5;241m=\u001b[39mprocessed_images, text\u001b[38;5;241m=\u001b[39mprompts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, torch\u001b[38;5;241m.\u001b[39mbfloat16)\n",
      "\u001b[0;31mValueError\u001b[0m: Local file not found: ../assets/xinfer.jg"
     ]
    }
   ],
   "source": [
    "image = \"https://raw.githubusercontent.com/vikhyat/moondream/main/assets/demo-1.jpg\"\n",
    "prompt = \"Describe this image. Answer:\"\n",
    "# prompt = \"<grounding> An image of\"\n",
    "\n",
    "image = \"../assets/xinfer.jp\"\n",
    "\n",
    "generated_text = model.infer(image, prompt, verbose=True)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-14 12:40:45.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxinfer.transformers.auto\u001b[0m:\u001b[36minfer_batch\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mInference time: 537.8785 ms\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer',\n",
       " 'xinfer']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "images = [image] * batch_size\n",
    "prompts = [prompt] * batch_size\n",
    "\n",
    "model.infer_batch(images, prompts, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xinfer-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
